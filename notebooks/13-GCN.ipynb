{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88bd2589-9c42-4f78-b4d1-f8f1c9f9488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b86cc3b-c006-4f7e-85b6-2cd7b0c89685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d176955-6181-4f46-a2f9-af94d62f79a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "\n",
    "import openpyxl\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a4446eb-7f01-4ab4-97e2-5939e4774aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP = Path.cwd().as_posix().replace('notebooks','')\n",
    "raw_dir = Path(TOP) / 'data'/'raw'\n",
    "interim_dir = Path(TOP) / 'data'/'interim'\n",
    "external_dir = Path(TOP) / 'data'/'external'\n",
    "figures_dir = Path(TOP) / 'reports'/'figures/'\n",
    "processed_dir = Path(TOP) / 'data'/'processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76cfc4fc-4cee-406f-86d5-b2b0c2b0e192",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear, Sequential, BatchNorm1d, ReLU, Dropout\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GINConv\n",
    "from torch_geometric.nn import global_mean_pool, global_add_pool\n",
    "from torch_geometric.data import Data, Dataset, DataLoader\n",
    "from torch_geometric.transforms import Compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b51d4cd-f426-46e4-bfd2-44b8e3d7f70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import subgraph\n",
    "\n",
    "class RandomNodeDrop:\n",
    "    def __init__(self, p=0.2):\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, data):\n",
    "        # Randomly mask nodes\n",
    "        num_nodes = data.num_nodes\n",
    "        mask = torch.rand(num_nodes) > self.p  # Keep nodes with probability (1-p)\n",
    "        edge_index, _ = subgraph(mask, data.edge_index, relabel_nodes=True)\n",
    "        \n",
    "        # Update data object\n",
    "        data.edge_index = edge_index\n",
    "        if data.x is not None:  # Update node features if present\n",
    "            data.x = data.x[mask]\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd943b61-a3ab-423e-a22e-5c3a1eabddeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomEdgeDelete:\n",
    "    def __init__(self, p=0.2):\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, data):\n",
    "        num_edges = data.edge_index.size(1)\n",
    "        mask = torch.rand(num_edges) > self.p\n",
    "\n",
    "        #print(f\"Original edge_index shape: {data.edge_index.shape}\")\n",
    "        #print(f\"Original edge_attr shape: {data.edge_attr.shape if data.edge_attr is not None else 'None'}\")\n",
    "        #print(f\"Mask shape: {mask.shape}\")\n",
    "\n",
    "        # Apply mask to edge_index\n",
    "        data.edge_index = data.edge_index[:, mask]\n",
    "\n",
    "        # Apply mask to edge_attr (if present)\n",
    "        if data.edge_attr is not None:\n",
    "            data.edge_attr = data.edge_attr[mask]\n",
    "\n",
    "        #print(f\"New edge_index shape: {data.edge_index.shape}\")\n",
    "        #print(f\"New edge_attr shape: {data.edge_attr.shape if data.edge_attr is not None else 'None'}\")\n",
    "\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00925ad4-607f-44f3-b5bc-674cf8c54306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple GCN model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d43139d4-aa86-4801-a26c-525cdbc86c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mol_to_graph(mol):\n",
    "        \"\"\"\n",
    "        Converts an RDKit mol object into a graph representation with atom and bond features.\n",
    "        \n",
    "        :param mol: RDKit mol object representing a molecule.\n",
    "        :return: PyTorch Geometric Data object containing graph representation of the molecule.\n",
    "        \"\"\"\n",
    "        atom_features = []\n",
    "        bond_features = []\n",
    "        edge_index = []\n",
    "        \n",
    "        # Atom feature extraction\n",
    "        for atom in mol.GetAtoms():\n",
    "            atom_feature = [\n",
    "                atom.GetAtomicNum(),                         # Atomic number\n",
    "                atom.GetFormalCharge(),                      # Formal charge\n",
    "                atom.GetHybridization().real,                # Hybridization\n",
    "                atom.GetIsAromatic(),                        # Aromaticity\n",
    "                atom.GetImplicitValence(),                   # Implicit valence\n",
    "                atom.GetDegree(),                            # Number of bonds to other atoms\n",
    "                atom.IsInRing(),                             # Is in ring\n",
    "                atom.GetChiralTag(),                         # Chirality\n",
    "                atom.GetExplicitValence(),                   # Explicit valence\n",
    "                atom.GetNumRadicalElectrons(),               # Number of radical electrons\n",
    "                atom.GetTotalNumHs(),                        # Total number of hydrogens\n",
    "                atom.GetIsotope(),                           # Isotope (if any)\n",
    "                atom.GetMass()                               # Atomic mass\n",
    "            ]\n",
    "            atom_features.append(atom_feature)\n",
    "        \n",
    "        # Bond feature extraction\n",
    "        for bond in mol.GetBonds():\n",
    "            i = bond.GetBeginAtomIdx()\n",
    "            j = bond.GetEndAtomIdx()\n",
    "            edge_index.extend([[i, j], [j, i]])  # Add bidirectional edges\n",
    "            \n",
    "            bond_feature = [\n",
    "                bond.GetBondTypeAsDouble(),                  # Bond type (single, double, triple, aromatic)\n",
    "                bond.GetIsConjugated(),                      # Is conjugated\n",
    "                bond.IsInRing(),                             # Is in ring\n",
    "                bond.GetStereo(),                            # Bond stereochemistry (cis/trans)\n",
    "                bond.GetBondDir()                            # Bond direction (up/down in 3D)\n",
    "            ]\n",
    "            bond_features.extend([bond_feature, bond_feature])  # Add twice for bidirectional edges\n",
    "        \n",
    "        # Convert to tensors\n",
    "        x = torch.tensor(atom_features, dtype=torch.float)\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "        edge_attr = torch.tensor(bond_features, dtype=torch.float)\n",
    "        \n",
    "        return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09484a7c-8dc0-4608-98ed-c1dac61c4efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph contrastive learning loss\n",
    "def contrastive_loss(z1, z2, temperature=0.5, hard_negatives=None):\n",
    "    # Normalize embeddings\n",
    "    z1 = F.normalize(z1, dim=-1)\n",
    "    z2 = F.normalize(z2, dim=-1)\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    similarity_matrix = torch.mm(z1, z2.t())\n",
    "\n",
    "    # Stabilize exp by subtracting max similarity\n",
    "    max_similarity = similarity_matrix.max(dim=1, keepdim=True)[0]\n",
    "    sim_exp = torch.exp((similarity_matrix - max_similarity) / temperature)\n",
    "\n",
    "    # Contrastive loss\n",
    "    if hard_negatives is not None:\n",
    "        # Optionally focus on hard negatives\n",
    "        hard_mask = hard_negatives.bool()\n",
    "        negative_samples = sim_exp.masked_select(hard_mask).sum(dim=1)\n",
    "    else:\n",
    "        all_samples = sim_exp.sum(dim=1)\n",
    "        positive_samples = torch.diag(sim_exp)\n",
    "        loss = -torch.log(positive_samples / all_samples).mean()\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da91191d-79de-45c2-95d8-c9c8c6cfe8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphData(Dataset):\n",
    "    def __init__(self, df):\n",
    "        \"\"\"\n",
    "        GraphData class inheriting from the Dataset class in PyTorch.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pandas.DataFrame\n",
    "            The dataframe containing the SMILES strings.\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.valid_indices = self._get_valid_indices()\n",
    "\n",
    "    def _get_valid_indices(self):\n",
    "        valid_indices = []\n",
    "        for idx in range(len(self.df)):\n",
    "            row = self.df.iloc[idx]\n",
    "            smiles = row['smiles']\n",
    "            try:\n",
    "                mol = Chem.MolFromSmiles(smiles)\n",
    "                if mol is None:\n",
    "                    raise ValueError(f\"Invalid SMILES: {smiles}\")\n",
    "                valid_indices.append(idx)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing SMILES {smiles}: {e}\")\n",
    "                continue  # Skip invalid SMILES\n",
    "        return valid_indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns the graph representation of the molecule.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        idx : int\n",
    "            Index of the valid sample.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        graph : torch_geometric.data.Data\n",
    "            The graph representation of the molecule.\n",
    "        \"\"\"\n",
    "        # Use valid index to get the actual row from the dataframe\n",
    "        valid_idx = self.valid_indices[idx]\n",
    "        row = self.df.iloc[valid_idx]\n",
    "        smiles = row['smiles']\n",
    "        \n",
    "        # Process the valid SMILES string\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        graph = mol_to_graph(mol)\n",
    "        \n",
    "        return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f91d3009-173e-4fce-8c98-68e7890fe296",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(external_dir/'dsstox_smiles_dec24.csv', index_col = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36a0ea62-e1c4-43a6-9b32-46dc99bacc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(external_dir/'toxcast_cleaned.csv', index_col = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f86003b-4ef7-415f-8541-36c079b6e76e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INPUT</th>\n",
       "      <th>FOUND_BY</th>\n",
       "      <th>DTXSID</th>\n",
       "      <th>PREFERRED_NAME</th>\n",
       "      <th>CASRN</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>QSAR_READY_SMILES</th>\n",
       "      <th>smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTXSID3042423</td>\n",
       "      <td>DSSTox_Substance_Id</td>\n",
       "      <td>DTXSID3042423</td>\n",
       "      <td>Sucrose octaacetate</td>\n",
       "      <td>126-14-7</td>\n",
       "      <td>[H][C@]1(O[C@]2(COC(C)=O)O[C@H](COC(C)=O)[C@@H...</td>\n",
       "      <td>CC(=O)OCC1OC(COC(C)=O)(OC2OC(COC(C)=O)C(OC(C)=...</td>\n",
       "      <td>CC(=O)OCC1OC(COC(C)=O)(OC2OC(COC(C)=O)C(OC(C)=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DTXSID3042477</td>\n",
       "      <td>DSSTox_Substance_Id</td>\n",
       "      <td>DTXSID3042477</td>\n",
       "      <td>Tolnaftate</td>\n",
       "      <td>2398-96-1</td>\n",
       "      <td>CN(C(=S)OC1=CC2=CC=CC=C2C=C1)C1=CC=CC(C)=C1</td>\n",
       "      <td>CN(C(=S)OC1=CC2=CC=CC=C2C=C1)C1=CC=CC(C)=C1</td>\n",
       "      <td>CN(C(=S)OC1=CC2=CC=CC=C2C=C1)C1=CC=CC(C)=C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DTXSID3042508</td>\n",
       "      <td>DSSTox_Substance_Id</td>\n",
       "      <td>DTXSID3042508</td>\n",
       "      <td>Uric acid</td>\n",
       "      <td>69-93-2</td>\n",
       "      <td>O=C1NC2=C(N1)C(=O)NC(=O)N2</td>\n",
       "      <td>[H]N1C2C(=NC1=O)N([H])C(=O)N([H])C2=O</td>\n",
       "      <td>[H]N1C2C(=NC1=O)N([H])C(=O)N([H])C2=O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DTXSID3042631</td>\n",
       "      <td>DSSTox_Substance_Id</td>\n",
       "      <td>DTXSID3042631</td>\n",
       "      <td>(1R,3S)-3-(3,4-Dichlorophenyl)-N-methyl-2,3-di...</td>\n",
       "      <td>96850-13-4</td>\n",
       "      <td>Cl.CN[C@@H]1C[C@H](C2=CC=CC=C12)C1=CC=C(Cl)C(C...</td>\n",
       "      <td>CNC1CC(C2=CC=CC=C12)C1=CC(Cl)=C(Cl)C=C1</td>\n",
       "      <td>CNC1CC(C2=CC=CC=C12)C1=CC(Cl)=C(Cl)C=C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DTXSID3042633</td>\n",
       "      <td>DSSTox_Substance_Id</td>\n",
       "      <td>DTXSID3042633</td>\n",
       "      <td>Clomipramine hydrochloride</td>\n",
       "      <td>17321-77-6</td>\n",
       "      <td>Cl.CN(C)CCCN1C2=C(CCC3=C1C=C(Cl)C=C3)C=CC=C2</td>\n",
       "      <td>CN(C)CCCN1C2=CC=CC=C2CCC2=CC=C(Cl)C=C12</td>\n",
       "      <td>CN(C)CCCN1C2=CC=CC=C2CCC2=CC=C(Cl)C=C12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           INPUT             FOUND_BY         DTXSID  \\\n",
       "0  DTXSID3042423  DSSTox_Substance_Id  DTXSID3042423   \n",
       "1  DTXSID3042477  DSSTox_Substance_Id  DTXSID3042477   \n",
       "3  DTXSID3042508  DSSTox_Substance_Id  DTXSID3042508   \n",
       "4  DTXSID3042631  DSSTox_Substance_Id  DTXSID3042631   \n",
       "5  DTXSID3042633  DSSTox_Substance_Id  DTXSID3042633   \n",
       "\n",
       "                                      PREFERRED_NAME       CASRN  \\\n",
       "0                                Sucrose octaacetate    126-14-7   \n",
       "1                                         Tolnaftate   2398-96-1   \n",
       "3                                          Uric acid     69-93-2   \n",
       "4  (1R,3S)-3-(3,4-Dichlorophenyl)-N-methyl-2,3-di...  96850-13-4   \n",
       "5                         Clomipramine hydrochloride  17321-77-6   \n",
       "\n",
       "                                              SMILES  \\\n",
       "0  [H][C@]1(O[C@]2(COC(C)=O)O[C@H](COC(C)=O)[C@@H...   \n",
       "1        CN(C(=S)OC1=CC2=CC=CC=C2C=C1)C1=CC=CC(C)=C1   \n",
       "3                         O=C1NC2=C(N1)C(=O)NC(=O)N2   \n",
       "4  Cl.CN[C@@H]1C[C@H](C2=CC=CC=C12)C1=CC=C(Cl)C(C...   \n",
       "5       Cl.CN(C)CCCN1C2=C(CCC3=C1C=C(Cl)C=C3)C=CC=C2   \n",
       "\n",
       "                                   QSAR_READY_SMILES  \\\n",
       "0  CC(=O)OCC1OC(COC(C)=O)(OC2OC(COC(C)=O)C(OC(C)=...   \n",
       "1        CN(C(=S)OC1=CC2=CC=CC=C2C=C1)C1=CC=CC(C)=C1   \n",
       "3              [H]N1C2C(=NC1=O)N([H])C(=O)N([H])C2=O   \n",
       "4            CNC1CC(C2=CC=CC=C12)C1=CC(Cl)=C(Cl)C=C1   \n",
       "5            CN(C)CCCN1C2=CC=CC=C2CCC2=CC=C(Cl)C=C12   \n",
       "\n",
       "                                              smiles  \n",
       "0  CC(=O)OCC1OC(COC(C)=O)(OC2OC(COC(C)=O)C(OC(C)=...  \n",
       "1        CN(C(=S)OC1=CC2=CC=CC=C2C=C1)C1=CC=CC(C)=C1  \n",
       "3              [H]N1C2C(=NC1=O)N([H])C(=O)N([H])C2=O  \n",
       "4            CNC1CC(C2=CC=CC=C12)C1=CC(Cl)=C(Cl)C=C1  \n",
       "5            CN(C)CCCN1C2=CC=CC=C2CCC2=CC=C(Cl)C=C12  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef2b8e26-6f91-4e0c-8307-1711fb2eb8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34ed20e8-83f8-4d82-80bc-376f0e31da92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df1, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a50e70b-4adf-429f-b4d7-a24c1345aaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6847 entries, 4088 to 9476\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   INPUT              6847 non-null   object\n",
      " 1   FOUND_BY           6847 non-null   object\n",
      " 2   DTXSID             6847 non-null   object\n",
      " 3   PREFERRED_NAME     6847 non-null   object\n",
      " 4   CASRN              6847 non-null   object\n",
      " 5   SMILES             6847 non-null   object\n",
      " 6   QSAR_READY_SMILES  6847 non-null   object\n",
      " 7   smiles             6847 non-null   object\n",
      "dtypes: object(8)\n",
      "memory usage: 481.4+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a673637c-296e-47a0-b250-0ab595025d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22:07:40] Explicit valence for atom # 5 N, 5, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing SMILES OCC=C1C[NH]2(CC=C)CCC34C2CC1C1=CN2C5C(=CN(C31)C1=C4C=CC=C1)C1CC3C5(CC[NH]3(CC=C)CC1=CCO)C1=C2C=CC=C1: Invalid SMILES: OCC=C1C[NH]2(CC=C)CCC34C2CC1C1=CN2C5C(=CN(C31)C1=C4C=CC=C1)C1CC3C5(CC[NH]3(CC=C)CC1=CCO)C1=C2C=CC=C1\n"
     ]
    }
   ],
   "source": [
    "train_data = GraphData(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7b2656d-185b-4928-b493-3e88fefc8d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphData(6846)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02108559-9b86-44d4-b73d-bcb5f2ae90a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1712, 8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b0d7914-bc43-4652-a599-a4e648d304d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = GraphData(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a7019ad-1aca-4aaf-80be-97648116ee15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphData(1712)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31c02178-7c85-438a-b4c4-62062c5abc5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[14, 13], edge_index=[2, 32], edge_attr=[32, 5])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2f7725fc-50b8-4416-9c85-b9f2e1c31206",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomSubgraph:\n",
    "    def __init__(self, num_nodes: int):\n",
    "        self.num_nodes = num_nodes\n",
    "\n",
    "    def __call__(self, data):\n",
    "        import random\n",
    "        from torch_geometric.utils import subgraph\n",
    "\n",
    "        # Select random nodes from the graph\n",
    "        num_nodes = data.num_nodes\n",
    "        if self.num_nodes >= num_nodes:\n",
    "            return data  # Return the original graph if too few nodes to sample\n",
    "\n",
    "        random_nodes = random.sample(range(num_nodes), self.num_nodes)\n",
    "\n",
    "        # Generate subgraph\n",
    "        edge_index, edge_mask = subgraph(\n",
    "            random_nodes, edge_index=data.edge_index, relabel_nodes=True, num_nodes=num_nodes\n",
    "        )\n",
    "        # Create a new `Data` object to avoid modifying the input `data` in place\n",
    "        subgraph_data = Data()\n",
    "\n",
    "        # Update node features\n",
    "        if data.x is not None:\n",
    "            subgraph_data.x = data.x[random_nodes]\n",
    "\n",
    "        # Update edge index\n",
    "        subgraph_data.edge_index = edge_index\n",
    "\n",
    "        # Update edge attributes if present\n",
    "        if data.edge_attr is not None:\n",
    "            subgraph_data.edge_attr = data.edge_attr[edge_mask]\n",
    "\n",
    "        # Copy additional attributes (e.g., labels, targets)\n",
    "        for key in data.keys():  # Corrected here\n",
    "            if key not in ['x', 'edge_index', 'edge_attr']:\n",
    "                subgraph_data[key] = data[key]\n",
    "\n",
    "        return subgraph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd9efe27-a63a-405e-9a9f-b74c54cc15e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.transforms import RandomLinkSplit, RandomNodeSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8b87eead-27fd-45eb-936b-69019a3ecb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([RandomNodeSplit(split=\"train_rest\", num_train_per_class=5),RandomLinkSplit(is_undirected=True, add_negative_train_samples=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "40892bc5-29a7-485f-8b99-d5a5e14e3cc0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (3158717337.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[62], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    '''for i, graph in enumerate(train_data):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "'''for i, graph in enumerate(train_data):\n",
    "    print(f\"Graph {i} before transforms:\", graph)\n",
    "    try:\n",
    "        transformed_graph = transform(graph)\n",
    "        print(f\"Graph {i} after transforms:\", transformed_graph)\n",
    "    except Exception as e:\n",
    "        print(f\"Error with Graph {i}:\", e)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "93e5071d-d28e-4b4c-b9f4-5a4356c3f2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g1 type: <class 'torch_geometric.data.data.Data'>\n",
      "g2 type: <class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "for graph in train_data:\n",
    "    g1 = RandomNodeSplit(split=\"train_rest\", num_train_per_class=5)(graph)\n",
    "    g2 = RandomLinkSplit(is_undirected=True, add_negative_train_samples=False)(graph)\n",
    "    print(\"g1 type:\", type(g1))\n",
    "    print(\"g2 type:\", type(g2))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e3d7d938-c7e2-4f81-8b79-3e2bdf09c5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g2_pos type: <class 'torch_geometric.data.data.Data'>\n",
      "g2_neg type: <class 'torch_geometric.data.data.Data'>\n"
     ]
    }
   ],
   "source": [
    "for graph in train_data:\n",
    "    # Apply RandomNodeSplit to get one graph\n",
    "   # g1 = RandomNodeSplit(split=\"train_rest\", num_train_per_class=5)(graph)\n",
    "\n",
    "    # Apply RandomLinkSplit to get a tuple of graphs\n",
    "    split_graphs = RandomLinkSplit(is_undirected=True, add_negative_train_samples=False)(graph)\n",
    "    \n",
    "    # Access the positive and negative graphs from the tuple\n",
    "    g2_pos = split_graphs[0]\n",
    "    g2_neg = split_graphs[1]\n",
    "\n",
    "    print(\"g2_pos type:\", type(g2_pos))  # Positive links graph\n",
    "    print(\"g2_neg type:\", type(g2_neg))  # Negative links graph\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89055abb-7ba6-48a1-b3ca-7562509db787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # Filter out None values from the batch\n",
    "    batch = [item for item in batch if item is not None]\n",
    "    \n",
    "    if len(batch) == 0:\n",
    "        return None  # If no valid data left, return None (or you could return an empty batch)\n",
    "    \n",
    "    # Otherwise, proceed with the batch processing (you might need to adapt for your graph data)\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9de59d5b-0a11-4a57-a87e-05c9c3dce284",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grace/anaconda3/envs/pytorch_cuda/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=300, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=300, shuffle=False, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "af9588cc-e8e9-4a32-964c-1021701d9223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[5769, 13], edge_index=[2, 12084], edge_attr=[12084, 5], batch=[5769], ptr=[301])\n"
     ]
    }
   ],
   "source": [
    "for data in train_loader:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e47e61dc-dd43-4b65-afe4-ddf8572da6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, val_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            g1 = node_split_transform(batch)\n",
    "            g2_pos, g2_neg, _ = link_split_transform(batch)\n",
    "            z1 = model(g1.x, g1.edge_index)\n",
    "            z2 = model(g2_pos.x, g2_pos.edge_index)\n",
    "            loss = contrastive_loss(z1, z2)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d935c091-db1b-499e-b8d0-bd425577341e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 8.5105, Val Loss: 8.4104\n",
      "Epoch 2, Train Loss: 8.0451, Val Loss: 7.6298\n",
      "Epoch 3, Train Loss: 7.6068, Val Loss: 7.5699\n",
      "Epoch 4, Train Loss: 7.5448, Val Loss: 7.5250\n",
      "Epoch 5, Train Loss: 7.5012, Val Loss: 7.4835\n",
      "Epoch 6, Train Loss: 7.4615, Val Loss: 7.4409\n",
      "Epoch 7, Train Loss: 7.4201, Val Loss: 7.4046\n",
      "Epoch 8, Train Loss: 7.3823, Val Loss: 7.3703\n",
      "Epoch 9, Train Loss: 7.3494, Val Loss: 7.3451\n",
      "Epoch 10, Train Loss: 7.3274, Val Loss: 7.3299\n",
      "Epoch 11, Train Loss: 7.3093, Val Loss: 7.3064\n",
      "Epoch 12, Train Loss: 7.2936, Val Loss: 7.2866\n",
      "Epoch 13, Train Loss: 7.2832, Val Loss: 7.2788\n",
      "Epoch 14, Train Loss: 7.2794, Val Loss: 7.2844\n",
      "Epoch 15, Train Loss: 7.2673, Val Loss: 7.2618\n",
      "Epoch 16, Train Loss: 7.2580, Val Loss: 7.2576\n",
      "Epoch 17, Train Loss: 7.2508, Val Loss: 7.2528\n",
      "Epoch 18, Train Loss: 7.2436, Val Loss: 7.2471\n",
      "Epoch 19, Train Loss: 7.2396, Val Loss: 7.2381\n",
      "Epoch 20, Train Loss: 7.2337, Val Loss: 7.2344\n",
      "Epoch 21, Train Loss: 7.2319, Val Loss: 7.2272\n",
      "Epoch 22, Train Loss: 7.2267, Val Loss: 7.2221\n",
      "Epoch 23, Train Loss: 7.2221, Val Loss: 7.2241\n",
      "Epoch 24, Train Loss: 7.2148, Val Loss: 7.2164\n",
      "Epoch 25, Train Loss: 7.2162, Val Loss: 7.2168\n",
      "Epoch 26, Train Loss: 7.2108, Val Loss: 7.2104\n",
      "Epoch 27, Train Loss: 7.2032, Val Loss: 7.2104\n",
      "Epoch 28, Train Loss: 7.2066, Val Loss: 7.2037\n",
      "Epoch 29, Train Loss: 7.2043, Val Loss: 7.2012\n",
      "Epoch 30, Train Loss: 7.2006, Val Loss: 7.1999\n",
      "Epoch 31, Train Loss: 7.1925, Val Loss: 7.1945\n",
      "Epoch 32, Train Loss: 7.1890, Val Loss: 7.1892\n",
      "Epoch 33, Train Loss: 7.1835, Val Loss: 7.1836\n",
      "Epoch 34, Train Loss: 7.1868, Val Loss: 7.1881\n",
      "Epoch 35, Train Loss: 7.1792, Val Loss: 7.1806\n",
      "Epoch 36, Train Loss: 7.1789, Val Loss: 7.1836\n",
      "Epoch 37, Train Loss: 7.1770, Val Loss: 7.1769\n",
      "Epoch 38, Train Loss: 7.1736, Val Loss: 7.1804\n",
      "Epoch 39, Train Loss: 7.1738, Val Loss: 7.1740\n",
      "Epoch 40, Train Loss: 7.1699, Val Loss: 7.1726\n",
      "Epoch 41, Train Loss: 7.1687, Val Loss: 7.1706\n",
      "Epoch 42, Train Loss: 7.1721, Val Loss: 7.1701\n",
      "Epoch 43, Train Loss: 7.1671, Val Loss: 7.1693\n",
      "Epoch 44, Train Loss: 7.1656, Val Loss: 7.1699\n",
      "Epoch 45, Train Loss: 7.1647, Val Loss: 7.1683\n",
      "Epoch 46, Train Loss: 7.1660, Val Loss: 7.1648\n",
      "Epoch 47, Train Loss: 7.1620, Val Loss: 7.1657\n",
      "Epoch 48, Train Loss: 7.1637, Val Loss: 7.1683\n",
      "Epoch 49, Train Loss: 7.1625, Val Loss: 7.1647\n",
      "Epoch 50, Train Loss: 7.1584, Val Loss: 7.1611\n",
      "Epoch 51, Train Loss: 7.1591, Val Loss: 7.1643\n",
      "Epoch 52, Train Loss: 7.1560, Val Loss: 7.1611\n",
      "Epoch 53, Train Loss: 7.1584, Val Loss: 7.1630\n",
      "Epoch 54, Train Loss: 7.1570, Val Loss: 7.1640\n",
      "Epoch 55, Train Loss: 7.1595, Val Loss: 7.1609\n",
      "Epoch 56, Train Loss: 7.1617, Val Loss: 7.1622\n",
      "Epoch 57, Train Loss: 7.1551, Val Loss: 7.1587\n",
      "Epoch 58, Train Loss: 7.1577, Val Loss: 7.1640\n",
      "Epoch 59, Train Loss: 7.1622, Val Loss: 7.1615\n",
      "Epoch 60, Train Loss: 7.1577, Val Loss: 7.1590\n",
      "Epoch 61, Train Loss: 7.1590, Val Loss: 7.1575\n",
      "Epoch 62, Train Loss: 7.1566, Val Loss: 7.1644\n",
      "Epoch 63, Train Loss: 7.1558, Val Loss: 7.1599\n",
      "Epoch 64, Train Loss: 7.1557, Val Loss: 7.1585\n",
      "Epoch 65, Train Loss: 7.1563, Val Loss: 7.1580\n",
      "Epoch 66, Train Loss: 7.1536, Val Loss: 7.1553\n",
      "Epoch 67, Train Loss: 7.1540, Val Loss: 7.1582\n",
      "Epoch 68, Train Loss: 7.1538, Val Loss: 7.1561\n",
      "Epoch 69, Train Loss: 7.1541, Val Loss: 7.1558\n",
      "Epoch 70, Train Loss: 7.1539, Val Loss: 7.1566\n",
      "Epoch 71, Train Loss: 7.1536, Val Loss: 7.1583\n",
      "Epoch 72, Train Loss: 7.1520, Val Loss: 7.1558\n",
      "Epoch 73, Train Loss: 7.1551, Val Loss: 7.1589\n",
      "Epoch 74, Train Loss: 7.1537, Val Loss: 7.1576\n",
      "Epoch 75, Train Loss: 7.1497, Val Loss: 7.1550\n",
      "Epoch 76, Train Loss: 7.1541, Val Loss: 7.1533\n",
      "Epoch 77, Train Loss: 7.1554, Val Loss: 7.1543\n",
      "Epoch 78, Train Loss: 7.1534, Val Loss: 7.1553\n",
      "Epoch 79, Train Loss: 7.1518, Val Loss: 7.1539\n",
      "Epoch 80, Train Loss: 7.1513, Val Loss: 7.1535\n",
      "Epoch 81, Train Loss: 7.1514, Val Loss: 7.1546\n",
      "Epoch 82, Train Loss: 7.1503, Val Loss: 7.1541\n",
      "Epoch 83, Train Loss: 7.1528, Val Loss: 7.1541\n",
      "Epoch 84, Train Loss: 7.1506, Val Loss: 7.1542\n",
      "Epoch 85, Train Loss: 7.1531, Val Loss: 7.1541\n",
      "Epoch 86, Train Loss: 7.1498, Val Loss: 7.1521\n",
      "Epoch 87, Train Loss: 7.1523, Val Loss: 7.1536\n",
      "Epoch 88, Train Loss: 7.1511, Val Loss: 7.1518\n",
      "Epoch 89, Train Loss: 7.1511, Val Loss: 7.1513\n",
      "Epoch 90, Train Loss: 7.1506, Val Loss: 7.1545\n",
      "Epoch 91, Train Loss: 7.1518, Val Loss: 7.1522\n",
      "Epoch 92, Train Loss: 7.1524, Val Loss: 7.1536\n",
      "Epoch 93, Train Loss: 7.1506, Val Loss: 7.1522\n",
      "Epoch 94, Train Loss: 7.1523, Val Loss: 7.1527\n",
      "Epoch 95, Train Loss: 7.1480, Val Loss: 7.1516\n",
      "Epoch 96, Train Loss: 7.1500, Val Loss: 7.1530\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "index 5291 is out of bounds for dimension 0 with size 5261",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m loss \u001b[38;5;241m=\u001b[39m contrastive_loss(z1, z2)\n\u001b[1;32m     33\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 34\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     37\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_cuda/lib/python3.11/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_cuda/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_cuda/lib/python3.11/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: index 5291 is out of bounds for dimension 0 with size 5261"
     ]
    }
   ],
   "source": [
    "# Define transforms\n",
    "epochs = 100\n",
    "model = GCN(input_dim=train_data[0].num_features, hidden_dim=32, output_dim=16)\n",
    "node_split_transform = RandomNodeSplit(split=\"train_rest\", num_train_per_class=5)\n",
    "link_split_transform = RandomLinkSplit(is_undirected=True, add_negative_train_samples=False)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "# Model and optimizer\n",
    "\n",
    "\n",
    "\n",
    "# Contrastive learning loop\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        # Apply RandomNodeSplit for the first augmented graph\n",
    "        \n",
    "        g1 = node_split_transform(batch)\n",
    "\n",
    "        # Apply RandomLinkSplit to get positive and negative graphs\n",
    "        g2_pos, g2_neg, g2_val = link_split_transform(batch)\n",
    "\n",
    "        # Forward pass with positive graph\n",
    "        z1 = model(g1.x, g1.edge_index)  # Forward pass on the first graph (g1)\n",
    "        z2 = model(g2_pos.x, g2_pos.edge_index)  # Forward pass on the second graph (g2_pos)\n",
    "\n",
    "        # Compute contrastive loss with the positive graphs\n",
    "        loss = contrastive_loss(z1, z2)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Validation step\n",
    "    val_loss = validate_model(model, test_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {total_loss / len(train_loader):.4f}, Val Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    scheduler.step()\n",
    "# Backpropagation\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6032a25e-175d-4edd-b8cf-8500385a8778",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_weights_txcst.pth') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939d3f45-d7ff-4aa3-a02e-e48edfaea4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "import optuna\n",
    "\n",
    "# Define the model\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Training function\n",
    "def train_model(model, criterion, optimizer, train_loader, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "# Validation function\n",
    "def validate_model(model, criterion, val_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(val_loader)\n",
    "\n",
    "# Define the Optuna objective function\n",
    "def objective(trial):\n",
    "    # Hyperparameters to optimize\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 16, 128)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 16, 64)\n",
    "\n",
    "    # Data preparation\n",
    "    input_size = 10  # Example input features\n",
    "    output_size = 1  # Example output size (e.g., regression task)\n",
    "    dataset_size = 1000\n",
    "    x = torch.randn(dataset_size, input_size)\n",
    "    y = torch.randn(dataset_size, output_size)\n",
    "    dataset = TensorDataset(x, y)\n",
    "    train_size = int(0.8 * dataset_size)\n",
    "    val_size = dataset_size - train_size\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "    # Model, loss, optimizer\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = SimpleNet(input_size, hidden_size, output_size).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Training and validation\n",
    "    for epoch in range(10):  # Small number of epochs for testing\n",
    "        train_model(model, criterion, optimizer, train_loader, device)\n",
    "    val_loss = validate_model(model, criterion, val_loader, device)\n",
    "\n",
    "    return val_loss\n",
    "\n",
    "# Create an Optuna study and optimize\n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=50)\n",
    "\n",
    "    # Print the best parameters\n",
    "    print(\"Best hyperparameters:\", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd22b85d-8a3b-4542-9e31-37608207d329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ef2384-324a-4da3-8be4-43954a2f203e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483cded8-fdcb-49a2-88ba-274068e0ff2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dca979-7b82-40e6-8ad8-86762d4bb776",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0af081-9021-4c8e-ad33-fe6aa58991aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071290e1-f304-4ba9-9973-5c890f44ffcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_cuda",
   "language": "python",
   "name": "pytorch_cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
